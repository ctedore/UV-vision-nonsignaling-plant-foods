% This script reads in the full dataset 'plantFoodsData.mat' and the coefficients file generated by the 'generateCoeffs.m' script and 
% builds three tables which respectively contain:
% 1) RNL contrasts between all pairs of objects in each image ('RNLtable.mat')
% 2) Within-channel differences in receptor excitation between all pairs of objects in each image ('withinChannelTbl.mat')
% 3) If the 'animal' variable in line 9 is 'bird', double cone RNL contrasts and USML RNL color contrasts between all pairs of objects in 
%      each image ('dblCone_v_Color_table.mat'). This table is not generated if 'animal' variable is 'generalTetra'
% Each table also includes relevant metadata, such as sun elevation, cloud cover, etc..
% Also generated and saved is a file called 'ImageSetStruct.mat' that is 
% Only the 'animal' variable needs to be adjusted by the user.

%% USER ADJUSTABLE PARAMETER
animal = 'generalTetra'; % 'generalTetra' or 'bird'
%%
clearvars -except animal 
tic
%% loads downloaded imagesets structure and renames it 'data' 
imageSetFilename = 'plantFoodsData.mat'; % filename for downloaded imagesets structure
loadedData = load(imageSetFilename); % loads dataset
f = fieldnames(loadedData);
data = loadedData.(f{1:end}); % renames imageSets to 'data' for simplicity
clearvars -except data  animal % clears workspace of all variables except for 'data' and 'animal'

if strcmp(animal, 'generalTetra')
    % GENERALIZED TETRACHROMAT
    coeffFilename = 'generalTetraFilterCoefficients.mat'; % filename for computational filter coefficients
    numVisSystems = 2;
    u = 1;
    s = 2;
    m = 3;
    l = 4;
    dc = 0;
elseif strcmp(animal, 'bird')
   %  BIRDS - real single cones plus virtual double cone 
    coeffFilename = 'birdFilterCoefficients.mat'; % filename for computational filter coefficients
    numVisSystems = 4;
    dc = 1; % 1 if include double cone RNL contrast
    dcTableName = 'dblCone_v_Color_table.mat';
    chrComp = 3; % indicates which color vision system (see order calculated later in code) to compare DC contrast to.
    u = 1;
    s = 3;
    m = 5;
    l = 6;
    dcNumber = 7;
    % double cone noise estimates
    psittaciformeMean = mean([0.19 0.22]);
    galliformeMean = mean([0.165 0.2]);
    passeriforme = 0.34;
    piciforme = 0.29;
    columbiforme = 0.2;
    dcNoise = mean([psittaciformeMean galliformeMean passeriforme piciforme columbiforme]); 
end
withinTblFilename = strcat(animal, '_withinChannelTbl.mat');
RNLTblFilename = strcat(animal, '_RNLTbl.mat');

%% loads computational filter coefficients
loadedCoeffs = load(coeffFilename); % loads coefficients
f = fieldnames(loadedCoeffs);
coeffSet = loadedCoeffs.(f{1:end});
numVFilts = size(coeffSet,2);
numFilts = size(coeffSet,1);

%% calculates total number of possible object comparisons across all image sets
num_imagesets = length(data);
total_objcomb_length = 0;
total_objs = 0;
imageset_number = [];
for i = 1:num_imagesets
    numobjs = size(data(i).selection_data,1);  
    total_objs = total_objs + numobjs;
    objvect = (1:numobjs); % creates a vector of numbers from 1 to however many objects there are
    objcomb = nchoosek(objvect,2); % creates a matrix of all possible combinations of two objects
    objcomb_length = size(objcomb,1); % assesses number of object combinations
    total_objcomb_length = total_objcomb_length + objcomb_length;
end
total_objs

%% calculates median relative quantum catches for each object and stores them in new structure called ImageSetStruct
% preallocation
virtImg = cell(1,numVFilts);
weightedImgs = zeros(1036,1392,numFilts);
virtImgMean = zeros(numVFilts,1);
E = zeros(1, numVFilts);
artifSpp = 1;

for i = 1:num_imagesets    
    
    exposCorr = zeros(numFilts,1);       
    for f = 1:numFilts
        exposCorr(f) = 2000 / data(i).images(f).exposure; % calculates needed exposure correction for each image (since each image was taken with a different exposure). Note that 2000 is the max possible exposure on this camera
    end
        
    % creates virtual images and calculates the mean of each
    for vf = 1:numVFilts
        for f = 1:numFilts
            weightedImgs(:,:,f) = exposCorr(f) * data(i).images(f).image_matrix * coeffSet(f,vf);
        end
        virtImg{vf} = sum(weightedImgs,3);
        virtImgMean(vf) = mean2(virtImg{vf}(~isnan(virtImg{vf})));
        virtImg{vf} = virtImg{vf} / virtImgMean(vf);
    end
    
    % opponent comparison images
    U = virtImg{u} ./ (virtImg{u} + 1);
    S = virtImg{s} ./ (virtImg{s} + 1);
    M = virtImg{m} ./ (virtImg{m} + 1);
    L = virtImg{l} ./ (virtImg{l} + 1);
    clutterData(i).contrastImgs.US = reshape(U - S, 1442112,1);
    clutterData(i).contrastImgs.UM = reshape(U - M, 1442112,1);
    clutterData(i).contrastImgs.UL = reshape(U - L, 1442112,1);
    clutterData(i).contrastImgs.SM = reshape(S - M, 1442112,1);
    clutterData(i).contrastImgs.SL = reshape(S - L, 1442112,1);
    clutterData(i).contrastImgs.ML = reshape(M - L, 1442112,1);
    
    numobjs = size(data(i).selection_data,1);
    for j = 1:numobjs
        index = logical(data(i).selection_data(j).selected_pixel_file);
        index = reshape(index, 1036, 1392);
        for vf = 1:numVFilts
            q = virtImg{vf}(index); % median quantum catch
            q = median(q(~isnan(q)));
            E(vf) = q / (q + 1); % converted to receptor excitation
            eval(['ImageSetStruct(i).object(j).E', num2str(vf), ' = E(vf);']); % puts median receptor excitation for each virtual filter in a new structure called 'ImageSetStruct'
        end
        USobj = (E(u) - E(s));
        UMobj = (E(u) - E(m));
        ULobj = (E(u) - E(l));
        SMobj = (E(s) - E(m));
        SLobj = (E(s) - E(l));
        MLobj = (E(m) - E(l));
        clutterData(i).object(j).USobjdiff = USobj;
        clutterData(i).object(j).UMobjdiff = UMobj;
        clutterData(i).object(j).ULobjdiff = ULobj;
        clutterData(i).object(j).SMobjdiff = SMobj;
        clutterData(i).object(j).SLobjdiff = SLobj;
        clutterData(i).object(j).MLobjdiff = MLobj;
        
        % object category
        clutterData(i).object(j).objCat = data(i).selection_data(j).object; % object category
        
        % species
        if isempty(data(i).selection_data(j).species) && isempty(data(i).selection_data(j).alt_species_id) % if no species or alt_species_id indicated
            spp = num2str(artifSpp);
            artifSpp = artifSpp + 1;
        elseif isempty(data(i).selection_data(j).species) 
            spp = [num2str(i), '-', num2str(data(i).selection_data(j).alt_species_id)]; % if no species indicated
        else % if species indicated
            spp = data(i).selection_data(j).species;
        end
        ImageSetStruct(i).object(j).species = spp;
        clutterData(i).object(j).species = spp;
    end
end
save(['clutterData', '_', animal, '.mat'], 'clutterData', '-v7.3')

%% preallocation of vectors and cell arrays that will be filled in later and combined into a table   
imageset = zeros(total_objcomb_length,1);
directLightObj1 = zeros(total_objcomb_length,1);
directLightObj2 = zeros(total_objcomb_length,1);
obj1 = zeros(total_objcomb_length,1);
obj2 = zeros(total_objcomb_length,1);
species1 = cell(total_objcomb_length,1);
species2 = cell(total_objcomb_length,1);
obj1_class = cell(total_objcomb_length,1);
obj2_class = cell(total_objcomb_length,1);
habitat = cell(total_objcomb_length,1);
microhabitat = cell(total_objcomb_length,1);    
sunElev = zeros(total_objcomb_length,1);
sunOccl = zeros(total_objcomb_length,1);
cloudCover = zeros(total_objcomb_length,1);
site = cell(total_objcomb_length,1);
E1_contrast = zeros(total_objcomb_length,1);
E2_contrast = zeros(total_objcomb_length,1);
E3_contrast = zeros(total_objcomb_length,1);
E4_contrast = zeros(total_objcomb_length,1);
E5_contrast = zeros(total_objcomb_length,1);
E6_contrast = zeros(total_objcomb_length,1);
E7_contrast = zeros(total_objcomb_length,1);
RNLdc = zeros(total_objcomb_length,1);
RNL_contrast = zeros(total_objcomb_length*numVisSystems,1);

imageset_num = 0;
set1 = 1;
set2 = 1;
artifSpp = 1;
%%
for i = 1:num_imagesets
        
    numobjs = size(data(i).selection_data,1);   
    objvect = (1:numobjs); % creates a vector of numbers from 1 to however many objects there are
    objcomb = nchoosek(objvect,2); % creates a matrix of all possible combinations of two objects
    objcomb_length = size(objcomb,1); % assesses number of object combinations
    
    imageset_reps = repmat(data(i).id, [objcomb_length,1]);
    imageset_reps_length = length(imageset_reps);
    imageset(imageset_num+1:imageset_num+imageset_reps_length,1) = imageset_reps;

    %% fills habitat cell array with habitat type
    habitat(set1:set1+objcomb_length-1) = repmat({data(i).habitat}, [imageset_reps_length,1]); 
    
    %% fills microhabitat cell array with microhabitat type
    microhabitat(set1:set1+objcomb_length-1) = repmat({data(i).microhabitat}, [imageset_reps_length,1]);
    
    %% fills site cell array with the name of the site if available
    if isempty(data(i).location)
        site(set1:set1+objcomb_length-1) = repmat({''}, [imageset_reps_length,1]);
    else
        site(set1:set1+objcomb_length-1) = repmat({data(i).location}, [imageset_reps_length,1]);
    end
    
%%   
    for a = 1:objcomb_length       
        %% WITHIN-CHANNEL DIFFERENCES IN RECEPTOR OUTPUT BETWEEN OBJECTS 
        for n = 1:numVFilts
            eval(['E', num2str(n), '_1 = ImageSetStruct(i).object(objcomb(a,1)).E', num2str(n), ';']);
            eval(['E', num2str(n), '_2 = ImageSetStruct(i).object(objcomb(a,2)).E', num2str(n), ';']);
            
            eval(['E', num2str(n), '_contrast(set1) = (E', num2str(n), '_1-E', num2str(n), '_2);']);
        end
        
        %% BETWEEN-CHANNEL RNL COLOR CONTRASTS
        if strcmp(animal, 'bird')
            RNL_contrast(set2) = RNLcalcTet(E6_contrast(set1), E5_contrast(set1), E3_contrast(set1), E1_contrast(set1)); % tetrachromat with UV 
            RNL_contrast(set2+1) = RNLcalcTet(E6_contrast(set1), E5_contrast(set1), E3_contrast(set1), E2_contrast(set1)); % tetrachromat with UV 
            RNL_contrast(set2+2) = RNLcalcTet(E6_contrast(set1), E5_contrast(set1), E4_contrast(set1), E2_contrast(set1)); % tetrachromat with UV 
            RNL_contrast(set2+3) = RNLcalcTri(E6_contrast(set1), E5_contrast(set1), E4_contrast(set1)); % trichromat without UV
        elseif strcmp(animal, 'generalTetra')
            RNL_contrast(set2) = RNLcalcTri(E4_contrast(set1), E3_contrast(set1), E2_contrast(set1)); % trichromat without UV
            RNL_contrast(set2+1) = RNLcalcTet(E4_contrast(set1), E3_contrast(set1), E2_contrast(set1), E1_contrast(set1)); % tetrachromat with UV 
        end       
                
        %% RNL ACHROMATIC CONTRAST
        if dc == 1
            eval(['RNLdc(set1) = abs(E', num2str(dcNumber), '_contrast(set1) / dcNoise);']);
        end
        
        %% DofL (directness of lighting, i.e. whether object was illuminated by direct sunlight) 0 = indirect, 1 = direct, NaN = unrecorded/difficult to tell
        % first obj 
        if isempty(data(i).selection_data(objcomb(a,1)).sunlit)
            directLightObj1(set1,1) = missing;
        else
            directLightObj1(set1,1) = data(i).selection_data(objcomb(a,1)).sunlit;
        end       
        
        % second obj
        if isempty(data(i).selection_data(objcomb(a,2)).sunlit)
            directLightObj2(set1,1) = missing;
        else
            directLightObj2(set1,1) = data(i).selection_data(objcomb(a,2)).sunlit;
        end
        
        %% SUN ELEVATION
        sunElev(set1,1) = str2double(data(i).sun_elevation);
        
        %% SUN OCCLUSION
        if isempty(data(i).sun_occlusion)
            sunOccl(set1,1) = missing;
        else
            sunOccl(set1,1) = data(i).sun_occlusion;
        end
        
        %% CLOUD COVER
        if isempty(data(i).cloud_cover)
            cloudCover(set1,1) = missing;
        else
            cloudCover(set1,1) = data(i).cloud_cover;
        end
        
        %% UNIQUE ID
        % first object
        first_obj = data(i).selection_data(objcomb(a,1)).id;
        obj1(set1,1) = first_obj;
        
        % second object
        second_obj = data(i).selection_data(objcomb(a,2)).id;
        obj2(set1,1) = second_obj;
        
        %% SPECIES
        % first object 
        species1{set1,1} = ImageSetStruct(i).object(objcomb(a,1)).species;
       
        % second object 
        species2{set1,1} = ImageSetStruct(i).object(objcomb(a,2)).species;

        %% OBJECT CLASS (e.g. fruit, branches, etc)
        % first object 
        first_obj_class = data(i).selection_data(objcomb(a,1)).object;
        obj1_class{set1,1} = first_obj_class;
                
        % second object 
        second_obj_class = data(i).selection_data(objcomb(a,2)).object;
        obj2_class{set1,1} = second_obj_class;
        
%%  
        set1 = set1+1;
        set2 = set2+numVisSystems;
    end
    imageset_num = imageset_num + imageset_reps_length;
end
    
imageset = categorical(imageset);
obj1 = categorical(obj1);
obj2 = categorical(obj2);
species1 = categorical(species1);
species2 = categorical(species2);
site = categorical(site);
habitat = categorical(habitat);
microhabitat = categorical(microhabitat);
obj1_class = categorical(obj1_class);
obj2_class = categorical(obj2_class);
directLightObj1 = categorical(directLightObj1);
directLightObj2 = categorical(directLightObj2);

%% WITHIN-CHANNEL TABLE
if numVFilts == 7
    withinChTable = table(imageset, obj1, obj2, species1, species2, site, habitat, microhabitat, sunElev, sunOccl, cloudCover, obj1_class, obj2_class, directLightObj1, directLightObj2, E1_contrast, E2_contrast, E3_contrast, E4_contrast, E5_contrast, E6_contrast);
elseif numVFilts == 4
    withinChTable = table(imageset, obj1, obj2, species1, species2, site, habitat, microhabitat, sunElev, sunOccl, cloudCover, obj1_class, obj2_class, directLightObj1, directLightObj2, E1_contrast, E2_contrast, E3_contrast, E4_contrast);
end    
save(withinTblFilename, 'withinChTable')

%% RNL TABLES
subTable = table(imageset, obj1, obj2, species1, species2, site, habitat, microhabitat, sunElev, sunOccl, cloudCover, obj1_class, obj2_class, directLightObj1, directLightObj2);

if dc == 1
    contrast = vertcat(RNLdc, RNL_contrast(chrComp:numVisSystems:end));
    chrContrast = vertcat(zeros(total_objcomb_length,1), ones(total_objcomb_length,1));
    metadata =  vertcat(subTable, subTable);
    DC_v_color_table = horzcat(metadata, table(chrContrast, contrast));
    save(dcTableName, 'DC_v_color_table')
end

fullTable = cell(total_objcomb_length*numVisSystems, size(subTable,2));
clearvars -except subTable fullTable RNL_contrast total_objcomb_length numVisSystems RNLTblFilename testType animal
for i = 1:numVisSystems
    fullTable(i:numVisSystems:end,:) = table2cell(subTable);
end
fullTable = cell2table(fullTable);
fullTable.Properties.VariableNames = subTable.Properties.VariableNames;

if numVisSystems == 2 && strcmp(animal, 'generalTetra') 
    UVabsent = logical(repmat([1; 0], total_objcomb_length, 1));
    RNL = table(UVabsent, RNL_contrast);
elseif numVisSystems == 4 && strcmp(animal, 'bird')
    UVabsent = logical(repmat([0; 0; 0; 1], total_objcomb_length, 1));
    Vpresent = logical(repmat([0; 1; 1; 0], total_objcomb_length, 1));
    Svpresent = logical(repmat([0; 0; 1; 1], total_objcomb_length, 1));
    RNL = table(UVabsent, Vpresent, Svpresent, RNL_contrast);
end

RNLtable = horzcat(fullTable, RNL);
save(RNLTblFilename, 'RNLtable')
toc

%% FUNCTIONS

function deltaS = RNLcalcTet(delta4,delta3,delta2,delta1)

    % standard deviation of single photoreceptor noise 
    v = 0.12;
    
    % relative numbers of photoreceptor classes
    numU = 1;
    numS = 1.7;
    numM = 2.5;
    numL = 3;
    
    % noise in each channel
    e1 = v / sqrt(numU);
    e2 = v / sqrt(numS);
    e3 = v / sqrt(numM);
    e4 = v / sqrt(numL);
    
    % color contrast
    deltaS = sqrt((((e1*e2)^2)*((delta4-delta3)^2) + ((e1*e3)^2)*((delta4-delta2)^2) + ...
                   ((e1*e4)^2)*((delta3-delta2)^2) + ((e2*e3)^2)*((delta4-delta1)^2) + ...
                   ((e2*e4)^2)*((delta3-delta1)^2) + ((e3*e4)^2)*((delta2-delta1)^2)) / ...
                   (((e1*e2*e3)^2) + ((e1*e2*e4)^2) + ((e1*e3*e4)^2) + ((e2*e3*e4)^2))); 
end

function deltaS = RNLcalcTri(delta3,delta2,delta1)

    % standard deviation of single photoreceptor noise 
    v = 0.12;
    
    % relative numbers of photoreceptor classes
    numS = 1.7 + (1 * (1.7 / (1.7 + 2.5 + 3)));
    numM = 2.5 + (1 * (2.5 / (1.7 + 2.5 + 3)));
    numL = 3 + (1 * (3 / (1.7 + 2.5 + 3)));
    
    % noise in each channel
    e1 = v / sqrt(numS);
    e2 = v / sqrt(numM);
    e3 = v / sqrt(numL);
           
    % color contrast
    deltaS = sqrt(((e1^2)*((delta3-delta2)^2) + (e2^2)*((delta3-delta1)^2) + (e3^2)*((delta1-delta2)^2)) / ...
                   (((e1*e2)^2) + ((e1*e3)^2) + ((e2*e3)^2))); 
end