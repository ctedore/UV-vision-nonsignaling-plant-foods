# UV-vision-nonsignaling-plant-foods
code associated with Tedore C & Nilsson DE (2021). Ultraviolet vision aids the detection of nutrient-dense non-signaling plant foods. Vision Research, 183, 16–29.

### ‘Transmission1_17-01-05-004_UVS.txt’  
### ‘Transmission2_12-15-59-048_VS.txt’  
### ‘Transmission3_12-19-49-045_SWSu.txt’  
### ‘Transmission4_12-23-49-044_SWSv.txt’  
### ‘Transmission5_13-38-12-295_MWS.txt’  
### ‘Transmission6_13-42-12-285_LWS.txt’  

These are the transmittance spectra for the Spectrocam filterwheel filters. They are read in by the ‘generateCoeffs.m’ MATLAB script below.

**‘cameraComponentsSpectra.mat’

This is a MATLAB file that contains:
1\) the transmittance spectrum of the infrared blocking filter mounted on the front of the camera lens
2\) the transmittance spectrum of the CoastalOpt 60mm lens
3\) the spectral sensitivity of the JAI camera sensor.
This file is read in by the ‘generateCoeffs.m’ MATLAB script below.

**‘generateCoeffs.m’

This is a MATLAB script that:
1\) Reads in the transmittance spectra of the camera filters (files starting with 'Transmission*.txt')
2\) Reads in the spectral characteristics of all other camera components from the file 'cameraComponentsSpectra.mat'
3\) Calculates each camera channel's effective spectral sensitivity and saves them all in a file called ‘realFilters.mat’. This file is later read in by the ‘lightCollected.m’ script.
4\) Calculates avian spectral sensitivities or generalized tetrachromat spectral sensitivities, depending on how the user sets the 'animal' variable
5\) Finds a set of coefficients (all constrained to be >=0) that, when multiplied by the camera channel spectral sensitivities, and then summed, provides the best fit to the desired spectral sensitivities in the previous step
6\) Outputs these coefficients in a .mat file called ‘birdFilterCoefficients.mat’ or ‘generalTetraCoefficients.mat’ depending on which animal is specified. This file is later read in by the ‘build_tables.m’ script.
7\) Plots the desired and effective spectral sensitivities on top of each other and saves this as a jpeg file.
Only the 'animal' variable needs to be adjusted by the user.

**‘plantFoodsData.mat’

This is a MATLAB structure that contains the full dataset and associated metadata. Dark noise has already been subtracted from all pixels, and any HDR images have already been combined into single images. In addition, under- and over-exposed pixels have been replaced by NaN. This dataset is loaded by ‘build_tables.m’, ‘clutter.m’, and ‘environmentalDataHistograms.m’.

**‘build_tables.m’

This is a MATLAB script that reads in the full dataset 'plantFoodsData.mat' and the coefficients file generated by the 'generateCoeffs.m' script and builds three tables which respectively contain:
1\) RNL color contrasts (for different combinations of photoreceptor classes) between all pairs of objects in each image (outputs '*_RNLtable.mat')
2\) Within-channel differences in receptor excitation between all pairs of objects in each image (outputs '*_withinChannelTbl.mat')
3\) Double cone RNL contrasts and avian USML RNL color contrasts between all pairs of objects in each image ('dblCone_v_Color_table.mat'). This table is only generated if animal = ‘bird’.
Each table also includes relevant metadata, such as sun elevation, cloud cover, etc.
The script also saves a structure called ‘clutterData_*.mat’ which contains:
1\) Differences in receptor excitation values between the U cone and each of the S, M, and L cones for every pixel in every image
2\) Median differences in receptor excitation values between the U cone and each of the S, M, and L cones for each plant food.
Only the 'animal' variable needs to be adjusted by the user.

**‘withinChannel_figs_and_stats.m’

This is a MATLAB script that reads in the within-channel contrast table generated by the 'build_tables.m' script. It organizes the table, reclassifies specific botanical terms into broader categorizations, and limits comparisons to objects under similar illumination. It then plots the data and outputs the statistical analyses in the command window. The only parameter that needs to be adjusted by the user is the 'animal' parameter.

**‘RNL_figs_and_stats.m’

This is a MATLAB script that reads in the RNL color contrast table and, if animal='bird', it also reads in the double cone versus color contrast table, generated by the 'build_tables.m' script. It organizes the tables, reclassifies specific botanical terms into broader categorizations, and limits comparisons to objects under similar illumination. It then plots the data and outputs the statistical analyses in the command window. The only parameter that needs to be adjusted by the user is the 'animal' parameter.

**‘clutter.m’

This is a MATLAB script that loads the 'clutterData_*.mat' structure created by the 'build_tables.m' script, and generates histograms showing the distribution of the differences in receptor excitation values for each pixel across all images of the user-specified object category for all possible dichromatic receptor comparisons. The median value for the selected category of plant food is plotted as a vertical yellow line with the value printed on top of it. Also displayed it the percentage of image pixels falling below this median value. The user needs to specify 'animal' and 'objCat' and also to uncomment the single line in lines 47-51 that corresponds to the user-specified 'objCat'.

**‘environmentalDataHistograms.m’

This is a MATLAB script that reads in the 'plantFoodsData.mat' dataset and the 'bird_withinChannelTbl.mat' table, the latter of which is made by the 'build_tables.m script. From these, it extracts data on sun elevation, sun occlusion, and cloud cover for each image and object comparison and plots their distributions in histograms.

**‘developImgs_and_viewObjSelectns.m’

This is a MATLAB script that loads 'plantFoodsData.mat' and uses the image matrices within this structure to develop images for viewing on an sRGB display. The images developed by this script are designed to enable an objective assessment by eye on a computer display, but are not meant for quantitative analysis. The script writes the following images:
1\) grayscale images representing the receptor excitation of each of the avian photoreceptor classes; they are named '1_bird_U.png', '2_bird_V.png', '3_bird_Su.png', '4_bird_Sv.png', '5_bird_M.png', '6_bird_L.png'.
2\) two false-color images with three of the images in (1) plugged into each of the channels of the RGB display; they are named 'bird_LMS.png' and 'bird_LMU.png'.
3\) opponent comparison images; they are named 'bird_M-L.png', bird_S-L.png', 'bird_S-M.png', 'bird_U-L.png', 'bird_U-M.png', and 'bird_U-S.png'.
4\) one false-color image with S-U, M-L, and U-L opponent comparison images plugged into each of the channels of the RGB display.
5\) images showing which pixels were selected for color contrast calculations; each image shows the selected pixels for a single selection, with selected pixels at normal intensity and unselected pixels artificially darkened. All such images begin with 'obj' followed by the object's unique ID and categorization.
Note that the values of over- and under-exposed pixels have been replaced with NaN, which appear as white pixels in the developed images. For a detailed explanation of the logic and mathematics used to create the images in (1-3) above, see the Methods section of the associated manuscript.
